{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4c3ce3-9473-4fed-99b4-ddae5b2fc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61c7ea38-a64b-44f9-a1c1-659424bd1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = './data/hobbies_dep_sales.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "hobbies_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3acb34ba-f63d-42eb-9c9e-b20d2a43c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = './data/calendar.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "calendar_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682cafd7-2dc7-47ee-b7bb-0778deaa885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function used below, to slice and therefore standardize formats between dfs\n",
    "\n",
    "def day_slicer(row):\n",
    "    slice_list = row.split(\"_\")\n",
    "    return slice_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "649e1104-09fe-4659-9141-93a9b5854254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calendar_df['d'] = calendar_df['d'].apply(day_slicer)\n",
    "calendar_df['date'] = pd.to_datetime(calendar_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe4f3e91-08e8-4313-b159-ecf8ffec6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function fecthes the following attributes from calendar_df and pastes them to sales_df\n",
    "# snap, based on state\n",
    "# weekday and if is_weekend\n",
    "# events of each day, if any\n",
    "\n",
    "def fetch_calendar_info(row):\n",
    "    # Filter calendar_df for the matching date\n",
    "    calendar_row = calendar_df[calendar_df['date'] == row['date']]\n",
    "    \n",
    "    # Retrieve the relevant snap value based on the state\n",
    "    if not calendar_row.empty:\n",
    "        if row['state_id'] == 'CA':\n",
    "            row['snap'] = calendar_row['snap_CA'].values[0]\n",
    "        elif row['state_id'] == 'TX':\n",
    "            row['snap'] = calendar_row['snap_TX'].values[0]\n",
    "        elif row['state_id'] == 'WI':\n",
    "            row['snap'] = calendar_row['snap_WI'].values[0]\n",
    "        \n",
    "    # Fetching add weekday from calendar_df\n",
    "        row['weekday'] = calendar_row['weekday'].values[0]\n",
    "\n",
    "    # Fetching Event_1\n",
    "        row[\"event_name_1\"] = calendar_row[\"event_name_1\"].values[0]\n",
    "        row[\"event_type_1\"] = calendar_row[\"event_type_1\"].values[0]\n",
    "\n",
    "    # Fetching Event_2, if it is not NaN\n",
    "        row[\"event_name_2\"] = calendar_row[\"event_name_2\"].values[0]\n",
    "        row[\"event_type_2\"] = calendar_row[\"event_type_2\"].values[0]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "    # Empty Error Handling\n",
    "        row['snap'] = None  # or a default value\n",
    "        row['weekday'] = None\n",
    "        row[\"event_name_1\"] = None\n",
    "        row[\"event_type_1\"] = None\n",
    "        row[\"event_name_2\"] = None\n",
    "        row[\"event_type_2\"] = None\n",
    "        \n",
    "\n",
    "    # Flag Weekend (Binary)\n",
    "    if row[\"weekday\"] == \"Saturday\" or row[\"weekday\"] == \"Sunday\":\n",
    "        row[\"is_weekend\"] = 1\n",
    "    else:\n",
    "        row[\"is_weekend\"] = 0\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536ee3a2-5626-45b1-a65f-e82af1ff4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume_l4w(array, weeks_fetched=4):\n",
    "    \n",
    "    days_fetched = 7*weeks_fetched\n",
    "    snip_end = len(array)\n",
    "    snip_start = snip_end - days_fetched\n",
    "\n",
    "    #List containing the values of the last 28 days\n",
    "    last_28_days = array[snip_start:snip_end].tolist()\n",
    "\n",
    "    # The Loop belows goes through the values of the last 28 days\n",
    "    # and sums them into 4 weeks\n",
    "    last_4_weeks = [0,0,0,0]\n",
    "\n",
    "    for index, day in enumerate(last_28_days):\n",
    "        if index < 6: ## Week 1 -> index 0 to 6\n",
    "            last_4_weeks[0] += day\n",
    "        elif index < 13: ## Week 2 -> index 7 to 13\n",
    "            last_4_weeks[1] += day\n",
    "        elif index < 20: ## Week 3 -> index 14 to 20\n",
    "            last_4_weeks[2] += day\n",
    "        else:\n",
    "            last_4_weeks[3] += day\n",
    "\n",
    "    # Rounding values before returning\n",
    "    for i in range(len(last_4_weeks)):\n",
    "        last_4_weeks[i] = round(last_4_weeks[i],2)\n",
    "\n",
    "    \n",
    "    return last_4_weeks, last_28_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0164fac5-20c9-4073-8b00-ba8fb7106ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096665, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hobbies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8d6d2c2-ee36-48cd-8f70-72a2d04c65d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HOBBIES_1_001', 'HOBBIES_1_002', 'HOBBIES_1_003', 'HOBBIES_1_004', 'HOBBIES_1_005', 'HOBBIES_1_006', 'HOBBIES_1_007', 'HOBBIES_1_008', 'HOBBIES_1_009', 'HOBBIES_1_010']\n"
     ]
    }
   ],
   "source": [
    "# Generate dynamic product codes in the format HOBBIES_1_XXX\n",
    "\n",
    "num_products = 10  # or any other number you want\n",
    "my_articles = [f'HOBBIES_1_{i:03}' for i in range(1, num_products + 1)]\n",
    "print(my_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f136693-7c06-4d0a-9d51-dad1310bbe38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_4444\\1909211254.py:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  temp_df['day_num'] = temp_df['day'].str.extract('d_(\\d+)').astype(int)\n"
     ]
    }
   ],
   "source": [
    "def the_model(dep_df, list_articles):\n",
    "\n",
    "    weeks = [\"Week 1\", \"Week 2\", \"Week 3\", \"Week 4\"]\n",
    "    data_gathering = {\n",
    "            'week': weeks,\n",
    "            'DUMMY': [1,2,3,4]\n",
    "        }\n",
    "\n",
    "    ### For each article in list_articles, this function executes its entire code\n",
    "\n",
    "    for article in list_articles:\n",
    "        temp_df = dep_df[dep_df['item_id'] == article]\n",
    "        #print(article)\n",
    "        #print(temp_df)\n",
    "        \n",
    "        # Convert the 'day' column to an integer representing the day number\n",
    "        temp_df['day_num'] = temp_df['day'].str.extract('d_(\\d+)').astype(int)\n",
    "\n",
    "        # Assume the first day is 2011-01-29, add the day numbers to get actual dates\n",
    "        start_date = datetime.datetime(2011, 1, 29)\n",
    "        temp_df['date'] = temp_df['day_num'].apply(lambda x: start_date + datetime.timedelta(days=x-1))\n",
    "\n",
    "        # Sort by id and date before creating rolling features\n",
    "        temp_df = temp_df.sort_values(by=['id', 'date'])\n",
    "\n",
    "        # Create a 7-day rolling average\n",
    "        temp_df['rolling_avg_7'] = temp_df.groupby('id')['sales'].transform(lambda x: x.rolling(7, min_periods=1).mean().round(2))\n",
    "        temp_df['rolling_avg_30'] = temp_df.groupby('id')['sales'].transform(lambda x: x.rolling(30, min_periods=1).mean().round(2))\n",
    "\n",
    "        # Making sure of datetime type\n",
    "        temp_df['date'] = pd.to_datetime(temp_df['date'])\n",
    "\n",
    "        # Executing fetch_calendar_info function\n",
    "        temp_df = temp_df.apply(fetch_calendar_info, axis=1)\n",
    "\n",
    "        ## START OF ACTUAL MODEL\n",
    "\n",
    "        # Defining targets, dropping leakage\n",
    "        target_column = 'rolling_avg_7'\n",
    "        columns_to_drop =  ['sales', 'rolling_avg_7', 'rolling_avg_30']\n",
    "        X = temp_df.drop(columns=[target_column])\n",
    "        y = temp_df[target_column]\n",
    "\n",
    "        X = pd.get_dummies(X)\n",
    "\n",
    "        # Training the model\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Extracting date features\n",
    "        X_train['day'] = X_train['date'].dt.day\n",
    "        X_train['month'] = X_train['date'].dt.month\n",
    "        X_train['year'] = X_train['date'].dt.year\n",
    "        \n",
    "        X_test['day'] = X_test['date'].dt.day\n",
    "        X_test['month'] = X_test['date'].dt.month\n",
    "        X_test['year'] = X_test['date'].dt.year\n",
    "\n",
    "        # Drop the original 'date' column after extracting features\n",
    "        X_train = X_train.drop(columns=['date'])\n",
    "        X_test = X_test.drop(columns=['date'])\n",
    "\n",
    "        # Initialize the Model: Set up the model with default parameters or customize them as needed.\n",
    "\n",
    "        model = XGBRegressor(\n",
    "        objective='reg:squarederror',  # Use 'reg:squarederror' for regression\n",
    "        n_estimators=100,              # Number of trees\n",
    "        learning_rate=0.1,             # Step size shrinkage\n",
    "        max_depth=5,                   # Maximum depth of trees\n",
    "        random_state=42,                # Seed for reproducibility\n",
    "        enable_categorical=True\n",
    "        )\n",
    "\n",
    "        best_grid = {'colsample_bytree': [1.0],\n",
    "             'learning_rate': [0.2],\n",
    "             'max_depth': [3],\n",
    "             'n_estimators': [500],\n",
    "             'reg_alpha': [0],\n",
    "             'reg_lambda': [1],\n",
    "             'subsample': [1.0]\n",
    "        }\n",
    "\n",
    "        \n",
    "        # Step 4: Set up GridSearchCV with TimeSeriesSplit\n",
    "        tscv = TimeSeriesSplit(n_splits=5)  # This respects the order of time-series data\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=best_grid,\n",
    "        cv=tscv,\n",
    "        scoring='neg_mean_absolute_percentage_error',  # Choose a scoring metric\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit GridSearchCV on the training data\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Retrieve the best model from GridSearchCV\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Getting Predictions\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        \n",
    "        # Predictions become readable\n",
    "        get_volume_l4w(y_pred)\n",
    "\n",
    "        #weeks = [\"Week 1\", \"Week 2\", \"Week 3\", \"Week 4\"]\n",
    "        days = list(range(1, 29))\n",
    "        volume_l4w = get_volume_l4w(y_pred)\n",
    "        last_4_weeks = get_volume_l4w(y_pred)[0]\n",
    "        last_28_days = get_volume_l4w(y_pred)[1]\n",
    "\n",
    "        temp_data = {\n",
    "            'week': weeks,\n",
    "            article: last_4_weeks\n",
    "        }\n",
    "\n",
    "        article_df = pd.DataFrame(temp_data)\n",
    "        print(article_df)\n",
    "\n",
    "        data_gathering[article] = last_4_weeks\n",
    "\n",
    "    ### OUT OF LOOP\n",
    "\n",
    "    spillback_df = pd.DataFrame(data_gathering)\n",
    "\n",
    "    return spillback_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8d624-d2d0-4f72-9631-9fdda0b6276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_4444\\1909211254.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df['day_num'] = temp_df['day'].str.extract('d_(\\d+)').astype(int)\n",
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_4444\\1909211254.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df['date'] = temp_df['day_num'].apply(lambda x: start_date + datetime.timedelta(days=x-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "     week  HOBBIES_1_001\n",
      "0  Week 1           2.73\n",
      "1  Week 2           1.30\n",
      "2  Week 3           1.50\n",
      "3  Week 4           1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_4444\\1909211254.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df['day_num'] = temp_df['day'].str.extract('d_(\\d+)').astype(int)\n",
      "C:\\Users\\rafae\\AppData\\Local\\Temp\\ipykernel_4444\\1909211254.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df['date'] = temp_df['day_num'].apply(lambda x: start_date + datetime.timedelta(days=x-1))\n"
     ]
    }
   ],
   "source": [
    "the_model(hobbies_df, my_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf50eb1-1b5f-4111-ba45-1849c30bcabc",
   "metadata": {},
   "source": [
    "___________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
