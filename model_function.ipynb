{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c83bfb15-5740-4496-a8ea-30a9ecdabbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f4c3ce3-9473-4fed-99b4-ddae5b2fc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import datetime\n",
    "#import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "#import numpy as np\n",
    "#from xgboost import XGBRegressor\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "#import joblib\n",
    "#import random\n",
    "#import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61c7ea38-a64b-44f9-a1c1-659424bd1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = './data/hobbies_dep_sales.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "hobbies_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3acb34ba-f63d-42eb-9c9e-b20d2a43c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = './data/calendar.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "calendar_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce815c03-43bd-4b5d-83a6-aae952a25064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_string(length=6):\n",
    "    # Generate a random string of letters and digits\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "682cafd7-2dc7-47ee-b7bb-0778deaa885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function used below, to slice and therefore standardize formats between dfs\n",
    "\n",
    "def day_slicer(row):\n",
    "    slice_list = row.split(\"_\")\n",
    "    return slice_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "649e1104-09fe-4659-9141-93a9b5854254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calendar_df['d'] = calendar_df['d'].apply(day_slicer)\n",
    "calendar_df['date'] = pd.to_datetime(calendar_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe4f3e91-08e8-4313-b159-ecf8ffec6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function fecthes the following attributes from calendar_df and pastes them to sales_df\n",
    "# snap, based on state\n",
    "# weekday and if is_weekend\n",
    "# events of each day, if any\n",
    "\n",
    "def fetch_calendar_info(row):\n",
    "    # Filter calendar_df for the matching date\n",
    "    calendar_row = calendar_df[calendar_df['date'] == row['date']]\n",
    "    \n",
    "    # Retrieve the relevant snap value based on the state\n",
    "    if not calendar_row.empty:\n",
    "        if row['state_id'] == 'CA':\n",
    "            row['snap'] = calendar_row['snap_CA'].values[0]\n",
    "        elif row['state_id'] == 'TX':\n",
    "            row['snap'] = calendar_row['snap_TX'].values[0]\n",
    "        elif row['state_id'] == 'WI':\n",
    "            row['snap'] = calendar_row['snap_WI'].values[0]\n",
    "        \n",
    "    # Fetching add weekday from calendar_df\n",
    "        row['weekday'] = calendar_row['weekday'].values[0]\n",
    "\n",
    "    # Fetching Event_1\n",
    "        row[\"event_name_1\"] = calendar_row[\"event_name_1\"].values[0]\n",
    "        row[\"event_type_1\"] = calendar_row[\"event_type_1\"].values[0]\n",
    "\n",
    "    # Fetching Event_2, if it is not NaN\n",
    "        row[\"event_name_2\"] = calendar_row[\"event_name_2\"].values[0]\n",
    "        row[\"event_type_2\"] = calendar_row[\"event_type_2\"].values[0]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "    # Empty Error Handling\n",
    "        row['snap'] = None  # or a default value\n",
    "        row['weekday'] = None\n",
    "        row[\"event_name_1\"] = None\n",
    "        row[\"event_type_1\"] = None\n",
    "        row[\"event_name_2\"] = None\n",
    "        row[\"event_type_2\"] = None\n",
    "        \n",
    "\n",
    "    # Flag Weekend (Binary)\n",
    "    if row[\"weekday\"] == \"Saturday\" or row[\"weekday\"] == \"Sunday\":\n",
    "        row[\"is_weekend\"] = 1\n",
    "    else:\n",
    "        row[\"is_weekend\"] = 0\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "536ee3a2-5626-45b1-a65f-e82af1ff4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_volume_l4w(array, weeks_fetched=4):\n",
    "    \n",
    "    days_fetched = 7*weeks_fetched\n",
    "    snip_end = len(array)\n",
    "    snip_start = snip_end - days_fetched\n",
    "\n",
    "    #List containing the values of the last 28 days\n",
    "    last_28_days = array[snip_start:snip_end].tolist()\n",
    "\n",
    "    # The Loop belows goes through the values of the last 28 days\n",
    "    # and sums them into 4 weeks\n",
    "    last_4_weeks = [0,0,0,0]\n",
    "\n",
    "    for index, day in enumerate(last_28_days):\n",
    "        if index < 6: ## Week 1 -> index 0 to 6\n",
    "            last_4_weeks[0] += day\n",
    "        elif index < 13: ## Week 2 -> index 7 to 13\n",
    "            last_4_weeks[1] += day\n",
    "        elif index < 20: ## Week 3 -> index 14 to 20\n",
    "            last_4_weeks[2] += day\n",
    "        else:\n",
    "            last_4_weeks[3] += day\n",
    "\n",
    "    # Rounding values before returning\n",
    "    for i in range(len(last_4_weeks)):\n",
    "        last_4_weeks[i] = round(last_4_weeks[i],2)\n",
    "\n",
    "    \n",
    "    return last_4_weeks, last_28_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0164fac5-20c9-4073-8b00-ba8fb7106ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1096665, 9)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hobbies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8d6d2c2-ee36-48cd-8f70-72a2d04c65d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HOBBIES_1_001', 'HOBBIES_1_002', 'HOBBIES_1_003', 'HOBBIES_1_004', 'HOBBIES_1_005', 'HOBBIES_1_006', 'HOBBIES_1_007', 'HOBBIES_1_008', 'HOBBIES_1_009', 'HOBBIES_1_010']\n"
     ]
    }
   ],
   "source": [
    "# Generate dynamic product codes in the format HOBBIES_1_XXX\n",
    "\n",
    "num_products = 10  # or any other number you want\n",
    "my_articles = [f'HOBBIES_1_{i:03}' for i in range(1, num_products + 1)]\n",
    "print(my_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2f136693-7c06-4d0a-9d51-dad1310bbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### THE MODEL FUNCTION\n",
    "\n",
    "def the_model(dep_df, list_articles, be_verbose=False, create_csv=False):\n",
    "\n",
    "    weeks = [\"Week 1\", \"Week 2\", \"Week 3\", \"Week 4\"]\n",
    "    data_gathering = {'week': weeks, 'DUMMY': [1, 2, 3, 4]}\n",
    "    start_date = datetime.datetime(2011, 1, 29)\n",
    "\n",
    "    for article in list_articles:\n",
    "        temp_df = dep_df[dep_df['item_id'] == article].copy()\n",
    "        \n",
    "        # Convert the 'day' column to integer day numbers\n",
    "        #temp_df['day_num'] = temp_df['day'].str.extract(r'd_(\\d+)').astype(int)\n",
    "        #temp_df['date'] = temp_df['day_num'].apply(lambda x: start_date + datetime.timedelta(days=x-1))\n",
    "        \n",
    "        temp_df.loc[:, 'day_num'] = temp_df['day'].str.extract(r'd_(\\d+)').astype(int)\n",
    "        temp_df.loc[:, 'date'] = temp_df['day_num'].apply(lambda x: start_date + datetime.timedelta(days=x-1))\n",
    "\n",
    "\n",
    "        # Sort by id and date before creating rolling features\n",
    "        temp_df = temp_df.sort_values(by=['id', 'date'])\n",
    "\n",
    "        # Create rolling averages\n",
    "        temp_df['rolling_avg_7'] = temp_df.groupby('id')['sales'].transform(lambda x: x.rolling(7, min_periods=1).mean().round(2))\n",
    "        temp_df['rolling_avg_30'] = temp_df.groupby('id')['sales'].transform(lambda x: x.rolling(30, min_periods=1).mean().round(2))\n",
    "\n",
    "        # Execute fetch_calendar_info function\n",
    "        temp_df = temp_df.apply(fetch_calendar_info, axis=1)\n",
    "\n",
    "        # Define targets, drop leakage\n",
    "        target_column = 'rolling_avg_7'\n",
    "        X = temp_df.drop(columns=[target_column, 'sales', 'rolling_avg_30'])\n",
    "        y = temp_df[target_column]\n",
    "\n",
    "        X = pd.get_dummies(X)\n",
    "        X['day'] = X['date'].dt.day\n",
    "        X['month'] = X['date'].dt.month\n",
    "        X['year'] = X['date'].dt.year\n",
    "        X = X.drop(columns=['date'])\n",
    "\n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Initialize and optimize model\n",
    "        model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "        \n",
    "        best_grid = {\n",
    "            'colsample_bytree': [1.0],\n",
    "            'learning_rate': [0.2],\n",
    "            'max_depth': [3],\n",
    "            'n_estimators': [500],\n",
    "            'reg_alpha': [0],\n",
    "            'reg_lambda': [1],\n",
    "            'subsample': [1.0]\n",
    "        }\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model, \n",
    "            param_grid=best_grid, \n",
    "            cv=tscv, \n",
    "            scoring='neg_mean_absolute_percentage_error', \n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and store results\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        last_4_weeks, last_28_days = get_volume_l4w(y_pred)\n",
    "\n",
    "        if be_verbose:\n",
    "            #print(f\"_________________________________________________\")\n",
    "            print(f\"Below, preliminary results for {article} product:\")\n",
    "            temp_data = {'week': weeks, article: last_4_weeks}\n",
    "            article_df = pd.DataFrame(temp_data)\n",
    "            print(article_df)\n",
    "            print(f\"_________________________________________________\")\n",
    "\n",
    "        data_gathering[article] = last_4_weeks\n",
    "\n",
    "    # Compile results into a DataFrame\n",
    "    spillback_df = pd.DataFrame(data_gathering)\n",
    "\n",
    "    # Save to CSV if specified\n",
    "    if create_csv:\n",
    "        filename = f\"outputs/output_{generate_random_string()}.csv\"\n",
    "        spillback_df.to_csv(filename, index=False)\n",
    "\n",
    "    return spillback_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8d624-d2d0-4f72-9631-9fdda0b6276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________\n",
      "Below, preliminary results for HOBBIES_1_001 product:\n",
      "     week  HOBBIES_1_001\n",
      "0  Week 1           2.53\n",
      "1  Week 2           1.45\n",
      "2  Week 3           1.66\n",
      "3  Week 4           1.73\n",
      "_________________________________________________\n",
      "_________________________________________________\n",
      "Below, preliminary results for HOBBIES_1_002 product:\n",
      "     week  HOBBIES_1_002\n",
      "0  Week 1           1.74\n",
      "1  Week 2           2.33\n",
      "2  Week 3           2.15\n",
      "3  Week 4           2.13\n",
      "_________________________________________________\n",
      "_________________________________________________\n",
      "Below, preliminary results for HOBBIES_1_003 product:\n",
      "     week  HOBBIES_1_003\n",
      "0  Week 1           0.72\n",
      "1  Week 2           0.37\n",
      "2  Week 3           0.63\n",
      "3  Week 4           1.46\n",
      "_________________________________________________\n",
      "_________________________________________________\n",
      "Below, preliminary results for HOBBIES_1_004 product:\n",
      "     week  HOBBIES_1_004\n",
      "0  Week 1          12.18\n",
      "1  Week 2          10.16\n",
      "2  Week 3          12.44\n",
      "3  Week 4          12.80\n",
      "_________________________________________________\n",
      "_________________________________________________\n",
      "Below, preliminary results for HOBBIES_1_005 product:\n",
      "     week  HOBBIES_1_005\n",
      "0  Week 1           5.87\n",
      "1  Week 2           6.29\n",
      "2  Week 3           6.67\n",
      "3  Week 4           8.11\n",
      "_________________________________________________\n",
      "_________________________________________________\n",
      "Below, preliminary results for HOBBIES_1_006 product:\n",
      "     week  HOBBIES_1_006\n",
      "0  Week 1           7.13\n",
      "1  Week 2           4.12\n",
      "2  Week 3           6.43\n",
      "3  Week 4          10.47\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "the_model(hobbies_df, my_articles, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf50eb1-1b5f-4111-ba45-1849c30bcabc",
   "metadata": {},
   "source": [
    "___________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
