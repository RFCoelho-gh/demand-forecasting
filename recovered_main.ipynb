{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f4c3ce3-9473-4fed-99b4-ddae5b2fc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "61c7ea38-a64b-44f9-a1c1-659424bd1f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = './data/sales_train_evaluation.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "sales_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3acb34ba-f63d-42eb-9c9e-b20d2a43c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = './data/calendar.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "calendar_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1010b948-704a-4e2c-97a8-6f29691ea27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "file_path = './data/sell_prices.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "prices_df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21420441-727c-4eb6-a999-1a526a14ef25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1932</th>\n",
       "      <th>d_1933</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1947 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id  d_1  d_2  d_3  d_4  ...  d_1932  d_1933  d_1934  d_1935  d_1936  \\\n",
       "0       CA    0    0    0    0  ...       2       4       0       0       0   \n",
       "1       CA    0    0    0    0  ...       0       1       2       1       1   \n",
       "\n",
       "   d_1937  d_1938  d_1939  d_1940  d_1941  \n",
       "0       0       3       3       0       1  \n",
       "1       0       0       0       0       0  \n",
       "\n",
       "[2 rows x 1947 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "05e32f25-3a3b-468b-ab90-0a13203f590b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 1947)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f69750a4-2fbc-4a53-bd4d-c8e9da446b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data from wide to long format, as to use days easier\n",
    "\n",
    "sales_long = sales_df.melt(\n",
    "    id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'],\n",
    "    var_name='day',\n",
    "    value_name='sales'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b32093ce-b5ca-4685-9eed-fcda9fdec98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat_id\n",
       "FOODS        27892170\n",
       "HOUSEHOLD    20322270\n",
       "HOBBIES      10966650\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_long[\"cat_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4aff8-a215-4ac4-b0b8-26606d6f464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_sales_long = sales_long[sales_long['cat_id'] == 'HOBBIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa0c32-35dd-4145-a540-1d6ffddf1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_sales_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa78fd9-05b7-437a-8643-480b931e57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_hobbies_sales_long = hobbies_sales_long[hobbies_sales_long['state_id'] == 'CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb418931-4950-48b6-a73c-33525340153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_hobbies_sales_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c3858-f153-4a40-ad49-26b108737dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All SKU in Hobbie Department, within Primary Store in California\n",
    "# About 1.1 M entries\n",
    "\n",
    "alpha_ca_hobbies_sales_long = ca_hobbies_sales_long[ca_hobbies_sales_long['store_id'] == 'CA_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b82db-28d5-43bb-8a79-83d843dda631",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_ca_hobbies_sales_long.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd6aa42-9bfa-4931-8878-86663267eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_ca_hobbies_sales_long[\"item_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d56ed9-bfa3-49a9-8265-b6ce340fc90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A specific single SKU in Hobbie Department, within Primary Store in California\n",
    "\n",
    "filtered_sales_df = alpha_ca_hobbies_sales_long[alpha_ca_hobbies_sales_long['item_id'] == 'HOBBIES_1_389']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b024b-a415-4e2e-ad9b-f5bb5d53b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sales_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c54acb-fdf1-4227-8185-2b96a2723129",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc273310-3064-49d8-b455-ba2698b843d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'day' column to an integer representing the day number\n",
    "filtered_sales_df['day_num'] = filtered_sales_df['day'].str.extract('d_(\\d+)').astype(int)\n",
    "\n",
    "# Assume the first day is 2011-01-29, add the day numbers to get actual dates\n",
    "start_date = datetime.datetime(2011, 1, 29)\n",
    "filtered_sales_df['date'] = filtered_sales_df['day_num'].apply(lambda x: start_date + datetime.timedelta(days=x-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24d3ce-5ac4-4876-9742-6233afbc1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by id and date before creating rolling features\n",
    "filtered_sales_df = filtered_sales_df.sort_values(by=['id', 'date'])\n",
    "\n",
    "# Create a 7-day rolling average\n",
    "filtered_sales_df['rolling_avg_7'] = filtered_sales_df.groupby('id')['sales'].transform(lambda x: x.rolling(7, min_periods=1).mean().round(2))\n",
    "filtered_sales_df['rolling_avg_30'] = filtered_sales_df.groupby('id')['sales'].transform(lambda x: x.rolling(30, min_periods=1).mean().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cafd7-2dc7-47ee-b7bb-0778deaa885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function used below, to slice and therefore standardize formats between dfs\n",
    "\n",
    "def day_slicer(row):\n",
    "    slice_list = row.split(\"_\")\n",
    "    return slice_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e1104-09fe-4659-9141-93a9b5854254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calendar_df['d'] = calendar_df['d'].apply(day_slicer)\n",
    "\n",
    "calendar_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c86fd-a68c-4977-95c1-22bafbeaab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sales_df['date'] = pd.to_datetime(filtered_sales_df['date'])\n",
    "calendar_df['date'] = pd.to_datetime(calendar_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f3e91-08e8-4313-b159-ecf8ffec6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function fecthes the following attributes from calendar_df and pastes them to sales_df\n",
    "# snap, based on state\n",
    "# weekday and if is_weekend\n",
    "# events of each day, if any\n",
    "\n",
    "def fetch_calendar_info(row):\n",
    "    # Filter calendar_df for the matching date\n",
    "    calendar_row = calendar_df[calendar_df['date'] == row['date']]\n",
    "    \n",
    "    # Retrieve the relevant snap value based on the state\n",
    "    if not calendar_row.empty:\n",
    "        if row['state_id'] == 'CA':\n",
    "            row['snap'] = calendar_row['snap_CA'].values[0]\n",
    "        elif row['state_id'] == 'TX':\n",
    "            row['snap'] = calendar_row['snap_TX'].values[0]\n",
    "        elif row['state_id'] == 'WI':\n",
    "            row['snap'] = calendar_row['snap_WI'].values[0]\n",
    "        \n",
    "    # Fetching add weekday from calendar_df\n",
    "        row['weekday'] = calendar_row['weekday'].values[0]\n",
    "\n",
    "    # Fetching Event_1\n",
    "        row[\"event_name_1\"] = calendar_row[\"event_name_1\"].values[0]\n",
    "        row[\"event_type_1\"] = calendar_row[\"event_type_1\"].values[0]\n",
    "\n",
    "    # Fetching Event_2, if it is not NaN\n",
    "        row[\"event_name_2\"] = calendar_row[\"event_name_2\"].values[0]\n",
    "        row[\"event_type_2\"] = calendar_row[\"event_type_2\"].values[0]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "    # Empty Error Handling\n",
    "        row['snap'] = None  # or a default value\n",
    "        row['weekday'] = None\n",
    "        row[\"event_name_1\"] = None\n",
    "        row[\"event_type_1\"] = None\n",
    "        row[\"event_name_2\"] = None\n",
    "        row[\"event_type_2\"] = None\n",
    "        \n",
    "\n",
    "    # Flag Weekend (Binary)\n",
    "    if row[\"weekday\"] == \"Saturday\" or row[\"weekday\"] == \"Sunday\":\n",
    "        row[\"is_weekend\"] = 1\n",
    "    else:\n",
    "        row[\"is_weekend\"] = 0\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82506321-d89c-4d61-bed7-85fa44d81173",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sales_df = filtered_sales_df.apply(fetch_calendar_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2bbbf-756b-4a19-ae07-f4cd1e87d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sales_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb40bc3-5f17-4627-b382-7cc29d4c4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_df.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0854a-103d-4869-b4d9-f4c830eb6d61",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e723fdcd-c468-4ebd-8a88-df76e4d95f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODEL STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7a1ac-5056-4d5b-a711-d2de9737e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Assume 'sales' is your target variable\n",
    "target_column = 'rolling_avg_7'\n",
    "columns_to_drop =  ['sales', 'rolling_avg_7', 'rolling_avg_30']\n",
    "X = filtered_sales_df.drop(columns=[target_column])\n",
    "y = filtered_sales_df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9144f62-7fbe-40a2-8e61-b0368d661556",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XGBoost works with numericals\n",
    "\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a1464-e3f2-406f-96be-5f7997ca6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c93b19-c0f3-413f-af5f-793a27578619",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['day'] = X_train['date'].dt.day\n",
    "X_train['month'] = X_train['date'].dt.month\n",
    "X_train['year'] = X_train['date'].dt.year\n",
    "\n",
    "X_test['day'] = X_test['date'].dt.day\n",
    "X_test['month'] = X_test['date'].dt.month\n",
    "X_test['year'] = X_test['date'].dt.year\n",
    "\n",
    "# Drop the original 'date' column after extracting features\n",
    "X_train = X_train.drop(columns=['date'])\n",
    "X_test = X_test.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f78053-fcea-4094-adc7-b9127e7a08bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Model: Set up the model with default parameters or customize them as needed.\n",
    "\n",
    "model = XGBRegressor(\n",
    "    objective='reg:squarederror',  # Use 'reg:squarederror' for regression\n",
    "    n_estimators=100,              # Number of trees\n",
    "    learning_rate=0.1,             # Step size shrinkage\n",
    "    max_depth=5,                   # Maximum depth of trees\n",
    "    random_state=42,                # Seed for reproducibility\n",
    "    enable_categorical=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13956b-25e2-4b49-befa-c88ed3e66b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [250, 500],              # Number of trees\n",
    "    'learning_rate': [0.01, 0.2],      # Step size shrinkage\n",
    "    'max_depth': [3, 10],                   # Maximum depth of trees\n",
    "    'subsample': [0.5, 1.0],                 # Fraction of samples for each tree\n",
    "    'colsample_bytree': [0.6, 1.0],          # Fraction of features for each tree\n",
    "    'reg_alpha': [0, 0.1],                  # L1 regularization\n",
    "    'reg_lambda': [1, 2]                     # L2 regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4874dc-e053-4c81-a565-5776a94b5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = {'colsample_bytree': [1.0],\n",
    "             'learning_rate': [0.2],\n",
    "             'max_depth': [3],\n",
    "             'n_estimators': [500],\n",
    "             'reg_alpha': [0],\n",
    "             'reg_lambda': [1],\n",
    "             'subsample': [1.0]\n",
    "}\n",
    "\n",
    "#Best Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 500, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4fca3-cd71-490c-ad1e-c6d365fa0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Set up GridSearchCV with TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)  # This respects the order of time-series data\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=best_grid,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_absolute_percentage_error',  # Choose a scoring metric\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Step 5: Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Retrieve the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6822d-7782-4c7e-b8db-dac3045c2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801bbb2-19af-4c4b-9fed-c28a47a35506",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f78e8f3-fe5e-4171-9c37-8800c9a24302",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_indices = y_test != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7f86b-f536-47f1-9cf1-fbe728dbcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE, Measures the average magnitude of errors in predictions, without considering their direction. Lower is better.\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# RMSE, Measures the average magnitude of errors, with a larger penalty for bigger errors. Lower is better.\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# R2, Indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. \n",
    "# A higher value, closer to 1, is generally better.\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# MAPE, measures the average percentage error and is useful for understanding error relative to actual values.\n",
    "# mape = np.mean(np.abs((y_test_no_zero - y_pred) / y_test)) * 100\n",
    "mape = np.mean(np.abs((y_test[non_zero_indices] - y_pred[non_zero_indices]) / y_test[non_zero_indices])) * 100\n",
    "\n",
    "print(\"Current Target Column:\", target_column)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5197d3fc-70dc-4ea9-9433-92465929ef67",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a1928-990e-4535-8304-a45aab2299d5",
   "metadata": {},
   "source": [
    "## Results\n",
    "##### Mean Absolute Error (MAE): 0.099\n",
    "\n",
    "**Interpretation:** On average, the modelâ€™s predictions of the 7-day rolling average sales are off by about 0.099 units. This is a low error, suggesting that the modelâ€™s predictions are quite close to the actual values.\n",
    "\n",
    "**Conclusion:** A low MAE indicates that the model is able to predict the rolling average fairly accurately, which is a good sign for stable and consistent demand forecasting.\n",
    "\n",
    "##### Root Mean Squared Error (RMSE): 0.165\n",
    "\n",
    "**Interpretation:** The RMSE value of 0.165 units indicates the average magnitude of error, with a larger penalty on larger errors (due to squaring). This value is higher than MAE, which is expected since RMSE gives more weight to larger errors.\n",
    "\n",
    "**Conclusion:** The low RMSE further suggests that the model is accurate, but there are some slightly larger errors that increase the RMSE relative to MAE. However, both MAE and RMSE are quite low, indicating a well-performing model.\n",
    "\n",
    "##### R-squared (RÂ²): 0.837\n",
    "\n",
    "**Interpretation:** An RÂ² of 0.837 means that the model explains about 83.7% of the variance in the 7-day rolling average sales. This is a strong value, as RÂ² ranges from 0 to 1, with values closer to 1 indicating a better fit.\n",
    "\n",
    "**Conclusion:** This high RÂ² suggests that the model captures the overall trends and patterns in sales very well. There is still about 16.3% of the variance unexplained, which could be due to random fluctuations or factors not included in the model.\n",
    "\n",
    "##### Mean Absolute Percentage Error (MAPE): 36.44%\n",
    "\n",
    "**Interpretation:** The MAPE of 36.44% indicates that, on average, the modelâ€™s predictions are off by about 36.44% relative to the actual values. This is a moderate percentage error.\n",
    "\n",
    "**Conclusion:** Although MAPE is somewhat high, itâ€™s not uncommon for daily sales data, especially if the sales values are small, as percentage errors can appear larger in these cases. Given the low MAE and RMSE, the model is likely performing well in terms of predicting the general trend, even if individual daily percentage errors are higher.\n",
    "\n",
    "#### Summary of the Model's Performance with Rolling Average Target\n",
    "\n",
    "**Overall Accuracy:** The model shows good accuracy, with low MAE and RMSE, and a high RÂ². This suggests that the model is effectively capturing the trends in sales as represented by the 7-day rolling average.\n",
    "\n",
    "**MAPE Considerations:** The MAPE is higher than we might ideally want, but given the low absolute error metrics (MAE and RMSE), this may be acceptable depending on the context. High MAPE can sometimes happen if sales values fluctuate or if there are low values in the data, as the percentage error can appear larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701bee9-c852-434c-a7ca-4277b4ce826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMINING RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c566b-fff8-4ea7-85e6-6363d16b7783",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, edgecolor='k')\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42630930-cacd-44d6-9f19-42171e2d458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f276fc9-65bb-4c11-9ca6-2371b09c40a3",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a361b46b-fa92-47a6-adb3-42bfd19ee237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
